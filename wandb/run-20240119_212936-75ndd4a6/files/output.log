Training hawkes transformer...
{'activation': 'softplus', 'batch_size': 4, 'd_k': 128, 'd_model': 256, 'd_rnn': 0, 'data': 'data/Breakfast/', 'device': 'cuda', 'dropout': 0.1, 'epochs': 35, 'learning_rate': 0.0001, 'n_head': 4, 'n_layers': 4, 'smooth': 0}
Loading All Datasets...
45 9
[ Epoch 1 ]


  - (Training)   :  71%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                            | 86/121 [00:05<00:01, 20.45it/s]


  - (Training)   :   0%|                                                                                                                                                                                                                          | 0/121 [00:00<?, ?it/s]
  - (Testing)     loglikelihood:  0.43369, accuracy:  0.57529, RMSE:  1.08971, elapse: 0.057 min
  - [Info] Maximum ll:  0.43369, Maximum accuracy:  0.57529, Minimum RMSE:  1.08971
improvement in epoch 1


  - (Validation) :   0%|                                                                                                                                                                                                                           | 0/32 [00:00<?, ?it/s]

  - (Training)   :   0%|                                                                                                                                                                                                         | 0/121 [00:00<?, ?it/s]
  - (Testing)     loglikelihood:  0.54870, accuracy:  0.59588, RMSE:  1.07262, elapse: 0.058 min
  - [Info] Maximum ll:  0.54870, Maximum accuracy:  0.59588, Minimum RMSE:  1.07262
improvement in epoch 2
Traceback (most recent call last):
  File "C:\Users\mich0003\Repos\BachelorPP\proactive\strategies\architecture\wandb\hawkes_training_wandb.py", line 61, in train
    train_event, train_type, train_time = train_epoch(model, trainloader, optimizer, pred_loss_func, pred_loss_goal, config, epoch)
  File "C:\Users\mich0003\Repos\BachelorPP\proactive\strategies\architecture\wandb\hawkes_training_wandb.py", line 107, in train_epoch
    desc='  - (Training)   ', leave=False):
  File "C:\Users\mich0003\AppData\Local\anaconda3\envs\proactive\lib\site-packages\tqdm\std.py", line 1178, in __iter__
    for obj in iterable:
  File "C:\Users\mich0003\AppData\Local\anaconda3\envs\proactive\lib\site-packages\torch\utils\data\dataloader.py", line 291, in __iter__
    return _MultiProcessingDataLoaderIter(self)
  File "C:\Users\mich0003\AppData\Local\anaconda3\envs\proactive\lib\site-packages\torch\utils\data\dataloader.py", line 737, in __init__
    w.start()
  File "C:\Users\mich0003\AppData\Local\anaconda3\envs\proactive\lib\multiprocessing\process.py", line 112, in start
    self._popen = self._Popen(self)
  File "C:\Users\mich0003\AppData\Local\anaconda3\envs\proactive\lib\multiprocessing\context.py", line 223, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "C:\Users\mich0003\AppData\Local\anaconda3\envs\proactive\lib\multiprocessing\context.py", line 322, in _Popen
    return Popen(process_obj)
  File "C:\Users\mich0003\AppData\Local\anaconda3\envs\proactive\lib\multiprocessing\popen_spawn_win32.py", line 89, in __init__
    reduction.dump(process_obj, to_child)
  File "C:\Users\mich0003\AppData\Local\anaconda3\envs\proactive\lib\multiprocessing\reduction.py", line 60, in dump
    ForkingPickler(file, protocol).dump(obj)
BrokenPipeError: [Errno 32] Broken pipe