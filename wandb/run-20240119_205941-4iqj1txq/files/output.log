Training hawkes transformer...
{'batch_size': 4, 'd_k': 128, 'd_model': 512, 'd_rnn': 0, 'data': 'data/Breakfast/', 'device': 'cuda', 'dropout': 0.1, 'epochs': 35, 'learning_rate': 0.0001, 'n_head': 4, 'n_layers': 4, 'num_mix_components': 32, 'smooth': 0}
Loading All Datasets...
45 9
tensor(-2.0079, device='cuda:0') tensor(1.7772, device='cuda:0')
[ Epoch 0 ]


  - (Training)   :  57%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                  | 69/121 [00:04<00:03, 16.91it/s]


  - (Training)   :   3%|██████                                                                                                                                                                                            | 1/32 [00:02<01:30,  2.93s/it]
Test loss: 15.236845016479492 with time_loss: -7.645028591156006 and type_loss 22.881874084472656



  - (Training)   :  55%|████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                       | 66/121 [00:04<00:03, 16.16it/s]

  - (Training)   :   0%|                                                                                                                                                                                                          | 0/32 [00:00<?, ?it/s]
Test loss: 9.651586532592773 with time_loss: -9.970369338989258 and type_loss 19.62195587158203



  - (Training)   :  55%|████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                       | 66/121 [00:04<00:03, 16.11it/s]


  - (Training)   :   0%|                                                                                                                                                                                                         | 0/121 [00:00<?, ?it/s]
Test loss: 10.460506439208984 with time_loss: -9.162622451782227 and type_loss 19.62312889099121



  - (Training)   :   0%|                                                                                                                                                                                                                           | 0/32 [00:00<?, ?it/s]


  - (Training)   :   0%|                                                                                                                                                                                                                          | 0/121 [00:00<?, ?it/s]
Test loss: 8.13044548034668 with time_loss: -10.194828033447266 and type_loss 18.325273513793945



  - (Training)   :   0%|                                                                                                                                                                                                                           | 0/32 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "C:\Users\mich0003\Repos\BachelorPP\proactive\strategies\architecture\wandb\gmm_training_wandb.py", line 73, in train
    time_loss, type_loss = eval_epoch(model, testloader, pred_loss_func, pred_loss_goal, config, event_data)
  File "C:\Users\mich0003\Repos\BachelorPP\proactive\strategies\architecture\wandb\gmm_training_wandb.py", line 127, in eval_epoch
    for  batch in tqdm(test_data, mininterval=2, desc='  - (Training)   ', leave=False):
  File "C:\Users\mich0003\AppData\Local\anaconda3\envs\proactive\lib\site-packages\tqdm\std.py", line 1178, in __iter__
    for obj in iterable:
  File "C:\Users\mich0003\AppData\Local\anaconda3\envs\proactive\lib\site-packages\torch\utils\data\dataloader.py", line 291, in __iter__
    return _MultiProcessingDataLoaderIter(self)
  File "C:\Users\mich0003\AppData\Local\anaconda3\envs\proactive\lib\site-packages\torch\utils\data\dataloader.py", line 737, in __init__
    w.start()
  File "C:\Users\mich0003\AppData\Local\anaconda3\envs\proactive\lib\multiprocessing\process.py", line 112, in start
    self._popen = self._Popen(self)
  File "C:\Users\mich0003\AppData\Local\anaconda3\envs\proactive\lib\multiprocessing\context.py", line 223, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "C:\Users\mich0003\AppData\Local\anaconda3\envs\proactive\lib\multiprocessing\context.py", line 322, in _Popen
    return Popen(process_obj)
  File "C:\Users\mich0003\AppData\Local\anaconda3\envs\proactive\lib\multiprocessing\popen_spawn_win32.py", line 89, in __init__
    reduction.dump(process_obj, to_child)
  File "C:\Users\mich0003\AppData\Local\anaconda3\envs\proactive\lib\multiprocessing\reduction.py", line 60, in dump
    ForkingPickler(file, protocol).dump(obj)
BrokenPipeError: [Errno 32] Broken pipe